[
    {
        "content": "<p>Hey, everyone. I'm doing some ETL in Julia, and things are a bit all over the place. I was wondering if there was any package out there  to sort of organize everything in a pipeline / workflow. I've seen some of this stuff in python (e.g. Luigi). I was wondering if there was anything in Julia. Any suggestions in code/organization are also welcomed :)</p>",
        "id": 279618193,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650498585
    },
    {
        "content": "<p>ETL extends for...?</p>",
        "id": 279704981,
        "sender_full_name": "Júlio Hoffimann",
        "timestamp": 1650558619
    },
    {
        "content": "<p>\"extraction transformation loading\"</p>",
        "id": 279705243,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650558733
    },
    {
        "content": "<p>I have to do a lot of this for my job.  <a href=\"https://github.com/search?q=DataFrames.jl&amp;type=Repositories\">DataFrames.jl</a> is wonderful, but I'm afraid there aren't any good options right now for out of memory stuff.</p>",
        "id": 279705365,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650558803
    },
    {
        "content": "<p>Most database stuff now implements <a href=\"https://github.com/JuliaDatabases/DBInterface.jl\">DBInterface</a> so that's been useful as well</p>",
        "id": 279705487,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650558847
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"273172\">@Júlio Hoffimann</span> , as <span class=\"user-mention\" data-user-id=\"269446\">@Expanding Man</span> said, it's pretty much the workflow where I take the raw data and do some transformations before training my model. There are some softwares that allows one to draw the actual pipe, which is good for documentation.</p>",
        "id": 279712848,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650562146
    },
    {
        "content": "<p>Thanks, <span class=\"user-mention\" data-user-id=\"269446\">@Expanding Man</span> , I'll take a look.</p>",
        "id": 279712878,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650562161
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"358317\">@Davi Sales Barreira</span> you mean tabular transformations? I think you are already aware of <a href=\"https://github.com/search?q=TableTransforms.jl&amp;type=Repositories\">TableTransforms.jl</a> right ?</p>",
        "id": 279713077,
        "sender_full_name": "Júlio Hoffimann",
        "timestamp": 1650562258
    },
    {
        "content": "<p>Yeah, ETL is usually before these types of transformations listed in <a href=\"https://github.com/search?q=TableTransforms.jl&amp;type=Repositories\">TableTransforms.jl</a>. I haven't actually used <a href=\"https://github.com/search?q=TableTransforms.jl&amp;type=Repositories\">TableTransforms.jl</a>, so perhaps it's adaptable to me case.<br>\nIn my case, my original data is actually an html file, which I then do a bunch of things in order to get a table. So it's more this pipeline from really raw data, to somewhat structured /e.g. table.</p>",
        "id": 279713550,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650562482
    },
    {
        "content": "<p>I mean, I have to use the html, and cross it with other datasets, and so on.</p>",
        "id": 279713604,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650562508
    },
    {
        "content": "<p>Can you give examples of things that e.g. Luigi could do for you that you'd like to be able to do?  My understanding was that most of the usefulness of packages like that is for handling distributed tasks and handling out of memory stuff, though it doesn't really sound like that's what you're describing.</p>",
        "id": 279714134,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650562755
    },
    {
        "content": "<p>A lot of that could be done with <a href=\"https://github.com/JuliaParallel/Dagger.jl\">Dagger.jl</a>, though you might still have to do significant setup work if you are trying to run it on a cluster.</p>",
        "id": 279714360,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650562859
    },
    {
        "content": "<p>Actually there will be out of memory stuff. But I'm not there yet, cause I'm still getting the code to parse the data.<br>\nSo, I have a bunch of html files in a S3 bucket, and json files. I also have some databases in Metabase.<br>\nI've downloaded a couple  of examples locally, and I'm writing some code that parses the information, cleans, structures and generates some new tables, that will be used for modelling.<br>\nNow, with time new html /json files will be sent to the S3 bucket, and from time to time there might be errors in the parsing. So I want to structure a pipeline that let's me organize this whole shebang.</p>",
        "id": 279723391,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650567032
    },
    {
        "content": "<p>I haven't actually used Luigi. But I read some of the docs, and it seems to do exactly the sort of stuff I just described.</p>",
        "id": 279723442,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650567069
    },
    {
        "content": "<p>It looks like <a href=\"https://github.com/search?q=Dagger.jl&amp;type=Repositories\">Dagger.jl</a> might help. Would you say it's already mature enough for doing production stuff?</p>",
        "id": 279724223,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650567460
    },
    {
        "content": "<p>I've started working for a startup and I'm in charge of the DS stuff. So I'm trying to use Julia for the most part.</p>",
        "id": 279724326,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650567505
    },
    {
        "content": "<p>I'm still having trouble understanding what it is you want to do that does not involve just writing a bunch of functions in a module somewhere.  If it's something you are planning on scaling up it might save you time in the long run if you start with <a href=\"https://github.com/search?q=Dagger.jl&amp;type=Repositories\">Dagger.jl</a> sooner rather than later, it scales down very well.  Its code base is a little messy in my opinion but it has been around for quite a while and is very actively maintained.</p>",
        "id": 279724897,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650567762
    },
    {
        "content": "<p>If your question is more about workflow: if I have a ton of tables I tend to pass them around in a big <code>Dict</code> of DataFrames along with some ancillary data (usually I create a <code>struct</code> for this).  When things are messy enough that has to get passed absolutely everywhere and winds up acting like a pseudo global state.</p>\n<p>This approach has worked pretty well for me, fortunately Julia doesn't really penalize you for having tons of accessible references in a function, even if they are poorly typed, type stability is only a problem if you access from an under-typed container.  Any function that doesn't do that is fine.  So even though the approach I described probably sounds super inefficient it's not that bad.</p>\n<p>Again, parallelism is a different issue.  I've messed around a bit with populating something like that using <a href=\"https://github.com/search?q=Dagger.jl&amp;type=Repositories\">Dagger.jl</a> but nothing at a very large scale.  It might be nice if we had a slightly-higher-level wrapper to <a href=\"https://github.com/search?q=Dagger.jl&amp;type=Repositories\">Dagger.jl</a> that made this a little easier, but I don't know what that would look like.  Like I said, I think the main use of the pipeline tools you were referring to like luigi (maybe dask?) has a lot more to do with managing tasks on a cluster.</p>",
        "id": 279727111,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650568894
    },
    {
        "content": "<p>One question that might help determine whether Dagger is sufficient for this use case is how much persistence/orchestration functionality you need for this ETL pipeline. Dagger has a <a href=\"https://juliaparallel.org/Dagger.jl/dev/scheduler-visualization/\">web dashboard</a> for tracking tasks, but to my knowledge no pipeline persistence like many Airflow-esque tools do. Think having a daemon that tracks when files are added to a bucket and can auto-feed them through the pipeline, plus can restart itself gracefully + log when it encounters errors. Yes all this can be done in with/without Dagger, but you'd have to roll more of your own code for it.</p>",
        "id": 279729264,
        "sender_full_name": "Brian Chen",
        "timestamp": 1650569929
    },
    {
        "content": "<p>Thanks again, <span class=\"user-mention\" data-user-id=\"269446\">@Expanding Man</span> . Now I get your point. I have two separate issues. The first one is indeed running in a cluster, with tasks that scales. And <a href=\"https://github.com/search?q=Dagger.jl&amp;type=Repositories\">Dagger.jl</a> seems to do that for me. The second problem is actually just writing a bunch of functions as you mentioned. So I was just wondering about how to \"organize\" the whole process of getting data from many locations and returning a clean table. Hence, it's more about organizing and documenting than actually coding. The tip on putting dataframes in a dict seems quite handy.</p>",
        "id": 279729999,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650570277
    },
    {
        "content": "<p>Opinions will differ, but for me a good bit of coding wisdom is not to be too eager to make things more complicated than they need to be.  Running your process in a huge distributed environment is probably going to be complicated, and there's probably no way around using <a href=\"https://github.com/search?q=Dagger.jl&amp;type=Repositories\">Dagger.jl</a> for that and even that you might find to be lacking features.  However if your intention is to run on one machine, simply getting it organized should not require anything that any programming language cannot already offer you.  For example, if you were doing this in python instead, I suspect it would be a bad move to use something like luigi or dask just to write a few functions down.</p>",
        "id": 279730545,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650570584
    },
    {
        "content": "<p>Though admittedly sometimes it can be hard to tell when exactly you've arrived at the point of actually needing something more complicated.</p>",
        "id": 279730626,
        "sender_full_name": "Expanding Man",
        "timestamp": 1650570605
    },
    {
        "content": "<p>Advice much appreciated!</p>",
        "id": 279756478,
        "sender_full_name": "Davi Sales Barreira",
        "timestamp": 1650586275
    },
    {
        "content": "<p>Have never used it and I'm not sure it's ever really taken off, but a package that advertises itself as \"clearing the pipeline jungle\" is <a href=\"https://github.com/search?q=FeatureTransforms.jl&amp;type=Repositories\">FeatureTransforms.jl</a>, which was presented at last year's JuliaCon (blog post including the talk <a href=\"https://invenia.github.io/blog/2021/08/10/juliacon2021/\">here</a>)</p>",
        "id": 279791662,
        "sender_full_name": "Nils",
        "timestamp": 1650614875
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"269446\">Expanding Man</span> <a href=\"#narrow/stream/274208-helpdesk-.28published.29/topic/Workflow.20.2F.20Pipeline.20for.20ETL.20in.20Julia/near/279727111\">said</a>:</p>\n</blockquote>\n<blockquote>\n<p>It might be nice if we had a slightly-higher-level wrapper to <a href=\"https://github.com/search?q=Dagger.jl&amp;type=Repositories\">Dagger.jl</a> that made this a little easier</p>\n</blockquote>\n<p>Fwiw, I use <a href=\"https://github.com/search?q=FileTrees.jl&amp;type=Repositories\">FileTrees.jl</a> alot for data wrangling. It is in itself a quite nice abstraction of the \"<code>Dict</code> of <code>DataFrames</code>\" with some very handy utilities for slicing around and map-reducing. </p>\n<p>It can make use <code>Dagger</code> to do stuff in parallel as well, so you can set up a lazy pipeline of transformations and let <a href=\"https://github.com/search?q=Dagger.jl&amp;type=Repositories\">Dagger.jl</a> produce the end result. I have found that it is very often possible to use the same code to do eager local processing on a smaller subset and then fire away at the whole dataset on a cluster when you think the code is correct. </p>\n<p>I can't vouch for any part of it being \"production grade\" though.</p>",
        "id": 279792242,
        "sender_full_name": "DrChainsaw",
        "timestamp": 1650615266
    },
    {
        "content": "<p>I recently came across <a href=\"https://github.com/search?q=Pipelines.jl&amp;type=Repositories\">Pipelines.jl</a> (<a href=\"https://cihga39871.github.io/Pipelines.jl/stable/\">https://cihga39871.github.io/Pipelines.jl/stable/</a>) which in turn mentions <a href=\"https://github.com/search?q=JobSchedulers.jl&amp;type=Repositories\">JobSchedulers.jl</a> . I'm not sure how relevant it is to your use case, as this is not my wheelhouse and I don't completely understand where each of these options stand, but maybe it's helpful <span aria-label=\"shrug\" class=\"emoji emoji-1f937\" role=\"img\" title=\"shrug\">:shrug:</span></p>",
        "id": 280598875,
        "sender_full_name": "Sundar R",
        "timestamp": 1651219503
    }
]