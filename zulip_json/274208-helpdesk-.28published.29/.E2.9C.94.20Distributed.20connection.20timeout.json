[
    {
        "content": "<p>Anyone has experience with debugging Distributed/Dagger jobs on a cluster?</p>\n<p>My task works when I use a small number of workers (10-40) but when I try to use more than that the thing pretty much always comes crashing down with \"Peer N didn't connect to M in X seconds\" at some point. Ideally I think I would like to be in the 500 range for maximum parallelism.</p>\n<p>Is it possible to log when and how much data is sent so I can get an overview of whether I overload the network or something? I have tried to set things up so that the bulk of the data is aggregated in the same Thunk before handing off, but maybe this is not enough. Increasing the timeout by a factor of 10 didn't help, but maybe things scale in some exponential fashion which is not clear to me.</p>\n<p>Assuming network loading is a problem, will concentrating workers on the same node help or will stuff anyways be sent over the network when passed between workers?</p>",
        "id": 258539111,
        "sender_full_name": "DrChainsaw",
        "timestamp": 1634820687
    },
    {
        "content": "<p>Fwiw, I found an <a href=\"https://github.com/shashi/FileTrees.jl/issues/60\">issue</a>  with the parallelism in my program where 95% of work ended up on a single worker. After fixing it I seem to be able to scale things up as much as I want to. Perhaps the worker was so overworked it could not respond?</p>",
        "id": 258697726,
        "sender_full_name": "DrChainsaw",
        "timestamp": 1634901787
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"300483\">DrChainsaw</span> has marked this topic as resolved.</p>",
        "id": 258697821,
        "sender_full_name": "Notification Bot",
        "timestamp": 1634901845
    }
]