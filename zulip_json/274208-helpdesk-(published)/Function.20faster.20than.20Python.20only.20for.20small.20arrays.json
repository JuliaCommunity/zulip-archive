[
    {
        "content": "<p>Any idea why this function is ~100x faster than Python for small arrays but the same for larger arrays?</p>\n<div class=\"codehilite\" data-code-language=\"Julia\"><pre><span></span><code><span class=\"k\">function</span> <span class=\"n\">hd_loss</span><span class=\"p\">(</span><span class=\"n\">ŷ</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">ŷ_dtm</span><span class=\"p\">,</span> <span class=\"n\">y_dtm</span><span class=\"p\">)</span>\n    <span class=\"n\">Δ</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">ŷ</span> <span class=\"o\">.-</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">.^</span> <span class=\"mi\">2</span>\n    <span class=\"n\">dtm</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">ŷ_dtm</span> <span class=\"o\">.^</span> <span class=\"mi\">2</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">y_dtm</span> <span class=\"o\">.^</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n\n    <span class=\"nd\">@tullio</span> <span class=\"n\">M</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">]</span> <span class=\"o\">:=</span> <span class=\"n\">Δ</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">dtm</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">]</span>\n    <span class=\"n\">hd_loss</span> <span class=\"o\">=</span> <span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">)</span>\n<span class=\"k\">end</span>\n</code></pre></div>\n<p>When I time it for small arrays <code>size = (4, 4, 2)</code> I get results ~100 faster than Python</p>\n<div class=\"codehilite\" data-code-language=\"Julia\"><pre><span></span><code><span class=\"nd\">@btime</span> <span class=\"n\">hd_loss</span><span class=\"p\">(</span><span class=\"n\">ŷ</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">ŷ_dtm</span><span class=\"p\">,</span> <span class=\"n\">y_dtm</span><span class=\"p\">)</span>\n\n<span class=\"c\"># 495.728 ns (6 allocations: 1.66 KiB)</span>\n</code></pre></div>\n<p>Compared to Python </p>\n<div class=\"codehilite\" data-code-language=\"Julia\"><pre><span></span><code><span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">hd_loss</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">y_hat</span><span class=\"p\">,</span> <span class=\"n\">gt_dtm</span><span class=\"p\">,</span> <span class=\"n\">seg_dtm</span><span class=\"p\">)</span>\n\n<span class=\"c\"># (36.6 µs ± 260 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each))</span>\n</code></pre></div>\n<p>When I time for larger arrays <code>size = (96, 96, 96)</code> I get results on par with Python</p>\n<div class=\"codehilite\" data-code-language=\"Julia\"><pre><span></span><code><span class=\"nd\">@btime</span> <span class=\"n\">hd_loss</span><span class=\"p\">(</span><span class=\"n\">Ŷ</span><span class=\"p\">,</span> <span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">Ŷ_dtm</span><span class=\"p\">,</span> <span class=\"n\">Y_dtm</span><span class=\"p\">)</span>\n\n<span class=\"c\"># 2.395 ms (55 allocations: 33.75 MiB)</span>\n</code></pre></div>\n<p>Compared to Python </p>\n<div class=\"codehilite\" data-code-language=\"Julia\"><pre><span></span><code><span class=\"o\">%</span><span class=\"n\">timeit</span> <span class=\"n\">hd_loss</span><span class=\"p\">(</span><span class=\"n\">large_y</span><span class=\"p\">,</span> <span class=\"n\">large_y_hat</span><span class=\"p\">,</span> <span class=\"n\">large_gt_dtm</span><span class=\"p\">,</span> <span class=\"n\">large_seg_dtm</span><span class=\"p\">)</span>\n\n<span class=\"c\"># 2.99 ms ± 130 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</span>\n</code></pre></div>",
        "id": 228019597,
        "sender_full_name": "Dale Black",
        "timestamp": 1614387298
    },
    {
        "content": "<p>Here is the Python function</p>\n<div class=\"codehilite\" data-code-language=\"Julia\"><pre><span></span><code><span class=\"n\">def</span> <span class=\"n\">hd_loss</span><span class=\"p\">(</span><span class=\"n\">seg_soft</span><span class=\"p\">,</span> <span class=\"n\">gt</span><span class=\"p\">,</span> <span class=\"n\">seg_dtm</span><span class=\"p\">,</span> <span class=\"n\">gt_dtm</span><span class=\"p\">)</span><span class=\"o\">:</span>\n    <span class=\"s\">\"\"\"</span>\n<span class=\"s\">    compute hausdorff distance loss for binary segmentation</span>\n<span class=\"s\">    \"\"\"</span>\n\n    <span class=\"n\">delta_s</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">seg_soft</span> <span class=\"o\">-</span> <span class=\"n\">gt</span><span class=\"p\">)</span> <span class=\"o\">**</span> <span class=\"mi\">2</span>\n    <span class=\"n\">s_dtm</span> <span class=\"o\">=</span> <span class=\"n\">seg_dtm</span> <span class=\"o\">**</span> <span class=\"mi\">2</span>\n    <span class=\"n\">g_dtm</span> <span class=\"o\">=</span> <span class=\"n\">gt_dtm</span> <span class=\"o\">**</span> <span class=\"mi\">2</span>\n    <span class=\"n\">dtm</span> <span class=\"o\">=</span> <span class=\"n\">s_dtm</span> <span class=\"o\">+</span> <span class=\"n\">g_dtm</span>\n    <span class=\"n\">multipled</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">einsum</span><span class=\"p\">(</span><span class=\"s\">\"xyz, xyz-&gt;xyz\"</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">from_numpy</span><span class=\"p\">(</span><span class=\"n\">delta_s</span><span class=\"p\">),</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">from_numpy</span><span class=\"p\">(</span><span class=\"n\">dtm</span><span class=\"p\">))</span>\n    <span class=\"n\">hd_loss</span> <span class=\"o\">=</span> <span class=\"n\">multipled</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">hd_loss</span>\n</code></pre></div>",
        "id": 228019798,
        "sender_full_name": "Dale Black",
        "timestamp": 1614387467
    },
    {
        "content": "<p>Python incurs an initial penalty because the code needs to be interpreted first. However, by the time you get to large matrices the initial overhead is now dominated by the calculation itself. In both languages most of that computation is actually being done in native code</p>",
        "id": 228020355,
        "sender_full_name": "Mark Kittisopikul",
        "timestamp": 1614387845
    },
    {
        "content": "<p>Ahh, okay thanks for clearing that up!</p>",
        "id": 228020854,
        "sender_full_name": "Dale Black",
        "timestamp": 1614388229
    },
    {
        "content": "<p>If you had tried to implement that <code>einsum</code> in Python itself, it would be painfully slow. Instead though, you call torch 's <code>einsum</code> which is implemented in C++</p>",
        "id": 228021034,
        "sender_full_name": "Mark Kittisopikul",
        "timestamp": 1614388369
    },
    {
        "content": "<p>Also, you shouldn't benchmark in global scope, instead you should use something like</p>\n<div class=\"codehilite\" data-code-language=\"Julia\"><pre><span></span><code><span class=\"nd\">@btime</span> <span class=\"n\">hd_loss</span><span class=\"p\">(</span><span class=\"o\">$</span><span class=\"n\">Ŷ</span><span class=\"p\">,</span> <span class=\"o\">$</span><span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"o\">$</span><span class=\"n\">Ŷ_dtm</span><span class=\"p\">,</span> <span class=\"o\">$</span><span class=\"n\">Y_dtm</span><span class=\"p\">)</span>\n</code></pre></div>",
        "id": 228029075,
        "sender_full_name": "Andrey Oskin",
        "timestamp": 1614396508
    },
    {
        "content": "<p>Hm, if you use views where applicable and in-place dotted functions, Julia should still be faster than Python.</p>",
        "id": 228043229,
        "sender_full_name": "Jakob Nybo Nissen",
        "timestamp": 1614414224
    },
    {
        "content": "<p>I haven't tried these, but I think you can avoid allocating 3 temporary arrays here, like so: </p>\n<div class=\"codehilite\" data-code-language=\"Julia\"><pre><span></span><code><span class=\"k\">function</span> <span class=\"n\">hd_loss_2</span><span class=\"p\">(</span><span class=\"n\">ŷ</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">ŷ_dtm</span><span class=\"p\">,</span> <span class=\"n\">y_dtm</span><span class=\"p\">)</span>\n    <span class=\"n\">M</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">ŷ</span> <span class=\"o\">.-</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">.^</span> <span class=\"mi\">2</span> <span class=\"o\">.*</span> <span class=\"p\">((</span><span class=\"n\">ŷ_dtm</span> <span class=\"o\">.^</span> <span class=\"mi\">2</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"n\">y_dtm</span> <span class=\"o\">.^</span> <span class=\"mi\">2</span><span class=\"p\">))</span>  <span class=\"c\"># allocates just one array</span>\n    <span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">M</span><span class=\"p\">)</span>\n<span class=\"k\">end</span>\n\n<span class=\"k\">function</span> <span class=\"n\">hd_loss_3</span><span class=\"p\">(</span><span class=\"n\">ŷ</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">ŷ_dtm</span><span class=\"p\">,</span> <span class=\"n\">y_dtm</span><span class=\"p\">)</span>\n    <span class=\"nd\">@tullio</span> <span class=\"n\">tot</span> <span class=\"o\">:=</span> <span class=\"p\">(</span><span class=\"n\">ŷ</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">,</span><span class=\"n\">k</span><span class=\"p\">]</span> <span class=\"o\">.-</span> <span class=\"n\">y</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">,</span><span class=\"n\">k</span><span class=\"p\">])</span><span class=\"o\">^</span><span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">ŷ_dtm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">,</span><span class=\"n\">k</span><span class=\"p\">]</span> <span class=\"o\">^</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">y_dtm</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">,</span><span class=\"n\">k</span><span class=\"p\">]</span> <span class=\"o\">^</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n    <span class=\"n\">hd_loss</span> <span class=\"o\">=</span> <span class=\"n\">tot</span> <span class=\"o\">/</span> <span class=\"n\">length</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span>\n<span class=\"k\">end</span>\n</code></pre></div>",
        "id": 228230329,
        "sender_full_name": "Michael Abbott",
        "timestamp": 1614605831
    },
    {
        "content": "<p>Thank you! That is much faster and easier to read</p>",
        "id": 228256814,
        "sender_full_name": "Dale Black",
        "timestamp": 1614614987
    }
]